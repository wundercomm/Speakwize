{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "es3sAB_4s3wO"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wundercomm/Speakwize/blob/main/tools/podcast-precess/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7v6UKkaOs3wY"
      },
      "source": [
        "# Detect GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOy8rx68s3wZ",
        "outputId": "bd9ad4a2-8b04-41c7-9044-507b126454d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Sep  4 19:38:41 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yO5wqat7s3we"
      },
      "source": [
        "# Install CondaColab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FjnGtM8s3wf",
        "outputId": "23eb0996-92f6-4813-a279-66dbbfeab871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:15\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "%pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z5ghw11as3wh"
      },
      "source": [
        "# Check CondaColab it's ok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqgcvBJWs3wi",
        "outputId": "7a8c3390-ed4f-439f-f67c-c01544810b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MFJh-JJ7s3wj"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUWurCyNs3wk",
        "outputId": "99062d28-ee18-4f87-fae5-1226653f517c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6k3ZR6egs3wm"
      },
      "outputs": [],
      "source": [
        "podcast_audio_directory = '/content/drive/MyDrive/AI/podcast/audio'\n",
        "podcast_text_directory = '/content/drive/MyDrive/AI/podcast/text'\n",
        "podcast_stats_csv = '/content/drive/MyDrive/AI/podcast/stats.csv'\n",
        "whisper_model = 'medium'\n",
        "decode_options = {\"language\": \"es\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JpZsmCts3wn"
      },
      "outputs": [],
      "source": [
        "!mkdir -p {podcast_audio_directory}\n",
        "!mkdir -p {podcast_text_directory}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qk0yTedis3wn"
      },
      "source": [
        "# Clone Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mO9wyDRs3wo",
        "outputId": "df8554b9-6623-430a-ad67-90b8dc7e422c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Speakwize'...\n",
            "remote: Enumerating objects: 314, done.\u001b[K\n",
            "remote: Counting objects: 100% (314/314), done.\u001b[K\n",
            "remote: Compressing objects: 100% (203/203), done.\u001b[K\n",
            "remote: Total 314 (delta 164), reused 231 (delta 90), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (314/314), 1.82 MiB | 5.69 MiB/s, done.\n",
            "Resolving deltas: 100% (164/164), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wundercomm/Speakwize"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2pSE38pCs3wo"
      },
      "source": [
        "# Install my env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMJig_42s3wp"
      },
      "outputs": [],
      "source": [
        "!mamba env update -n base -f /content/podcast-coffeebreak/environment.yml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rciOoJt2s3wp"
      },
      "source": [
        "# Check youtube-dl Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA2ubs3As3wq"
      },
      "outputs": [],
      "source": [
        "!youtube-dl --version"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PjlwbGyvs3wq"
      },
      "source": [
        "# Download Podcast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acNv51Mss3wr"
      },
      "outputs": [],
      "source": [
        "!bash /content/podcast-coffeebreak/utils/000_download_podcast.sh -u 'https://podcasts.google.com/feed/aHR0cDovL2ZlZWRzLmZlZWRidXJuZXIuY29tL1BvZGNhc3RDb2ZmZWVCcmVhaw?sa=X&ved=0CD4Q9sEGahcKEwjw1Zv4i8_6AhUAAAAAHQAAAAAQEw' -d /content/drive/MyDrive/AI/podcast/audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCSEkkh3s3wr",
        "outputId": "95b10c4a-1048-425e-ed90-dde7b16533a7"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2718330330.py, line 46)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 46\u001b[0;36m\u001b[0m\n\u001b[0;31m    transcribe_model=\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import whisper\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.DataFrame(columns=\n",
        "        [\n",
        "            'id',\n",
        "            'filename',\n",
        "            'audio_filename',\n",
        "            'text_filename',\n",
        "            'size_in_bytes',\n",
        "            'size_in_sconds',\n",
        "            'transcribe_status',\n",
        "            'transcribe_start',\n",
        "            'transcribe_end',\n",
        "            'transcribe_duration',\n",
        "            'transcribe_model',\n",
        "            'transcribe_language'\n",
        "        ]\n",
        ")\n",
        "df = df.set_index('id')\n",
        "model = whisper.load_model(whisper_model)\n",
        "\n",
        "for filename in sorted(os.listdir(podcast_audio_directory)):\n",
        "    id=filename.split('.')[0] + \"_\" + whisper_model\n",
        "    audio_filename = os.path.join(podcast_audio_directory, filename)\n",
        "    if not whisper_model == \"medium\":\n",
        "        text_filename = os.path.join(podcast_text_directory, filename.split('.')[0] + \"_\" + whisper_model + '.json')\n",
        "    else:\n",
        "        text_filename = os.path.join(podcast_text_directory, filename.split('.')[0] + '.json')\n",
        "    size_in_bytes = os.path.getsize(audio_filename)\n",
        "    # size_in_sconds=audio.info.length\n",
        "    df.loc[id]={\n",
        "            \"id\": id,\n",
        "            \"filename\": filename.split('.')[0],\n",
        "            \"audio_filename\": audio_filename,\n",
        "            \"text_filename\": text_filename,\n",
        "            \"size_in_bytes\": size_in_bytes,\n",
        "            # \"size_in_sconds\": size_in_sconds\n",
        "    }\n",
        "    if not os.path.exists(text_filename):\n",
        "        if os.path.isfile(audio_filename):\n",
        "            transcribe_start = time.time()\n",
        "            print('\\r transcribing {0} at {1}'.format(audio_filename, transcribe_start))\n",
        "            result = model.transcribe(audio_filename, **decode_options)\n",
        "            transcribe_end = time.time()\n",
        "            transcribe_duration = transcribe_end - transcribe_start\n",
        "            transcribe_status = \"1\"\n",
        "            transcribe_model=model\n",
        "            with open(text_filename, 'w',encoding='utf8') as text_filename_file:\n",
        "                print('\\r Writing {0}'.format(text_filename))\n",
        "                json.dump(result, text_filename_file, indent=4)\n",
        "            print('\\r end transcribe {0} at {1} duration of {2} sec'.format(audio_filename, transcribe_end, transcribe_duration))\n",
        "            df.loc[id]={\n",
        "                \"transcribe_status\": transcribe_status,\n",
        "                \"transcribe_start\": transcribe_start,\n",
        "                \"transcribe_end\": transcribe_end,\n",
        "                \"transcribe_duration\": transcribe_duration,\n",
        "                \"transcribe_model\": whisper_model,\n",
        "                \"transcribe_language\": decode_options[\"language\"]\n",
        "            }\n",
        "    df.to_csv(podcast_stats_csv, mode='a', index=True, header=True)\n",
        "    print(\"\\r {0} Data appended successfully\".format(id))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:35:26) [GCC 10.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "68796c4a74138b7d74b1ad1d89abe16eb1cdb3a820722abb0431af506d216224"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
